#Initiallizing the model
model =Sequential()
model.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=(100,100,3), activation='relu', padding = 'same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.6))
model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding = 'same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.6))
model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding = 'same'))
model.add(MaxPooling2D(pool_size=(2, 2)))


model.add(Flatten())

model.add(Dense(256))
model.add(Activation('relu'))
model.add(Dropout(0.6))

model.add(Dense(4,activation='softmax'))
model.compile(optimizer =Adam (learning_rate = 0.0001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

model.summary()

from tensorflow.keras.callbacks import EarlyStopping
early_stop=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=3)
#Early stopping to avoid overfitting of model
model_history=[]
n_fold= 3
for i in range (n_fold):
    print("Training on Fold: ",i+1)
    t_x, val_x, t_y, val_y = train_test_split(train_x, train_y, test_size=0.1, 
                                               random_state = np.random.randint(1,100, 1)[0])
    history = model.fit(
      t_x,
      t_y,
      validation_data=(val_x,val_y),
      epochs=10,
      callbacks=[early_stop],
      shuffle=True)
    model_history.append(history)

model.save('s.h5') #save model in h5

plt.figure(figsize=(12.7,7.2))
plt.title('Accuracies vs Epochs', color = 'white')
plt.plot(model_history[0].history['accuracy'], label='Training Fold 1')
plt.plot(model_history[1].history['accuracy'], label='Training Fold 2')
plt.plot(model_history[2].history['accuracy'], label='Training Fold 3')
plt.legend()
plt.xticks(color='white')
plt.yticks(color='white')
plt.show()
